# Appendix

## Glossary

* **Adversarial Attacks**: Malicious attempts to manipulate AI model inputs to produce incorrect or harmful outputs,
  exploiting vulnerabilities in data or model behavior.
* **Agentic AI**: Advanced AI systems capable of autonomous decision-making and continuous evolution through feedback
  loops, requiring robust governance.
* **Bias**: Unintended or unfair preferences in AI outputs, often arising from skewed training data, algorithms, or
  human oversight, potentially perpetuating discrimination.
* **Data Drift**: A gradual shift in the statistical properties of input data over time, which can reduce the accuracy, relevance, or stability of AI model predictions.
* **Data Poisoning**: The intentional insertion or manipulation of malicious data into a training dataset to degrade model performance or alter its outputs for malicious purposes.
* **Explainability**: The ability to provide clear, understandable reasons for AI decisions, enabling stakeholders to
  comprehend and trust outcomes.
* **Fairness**: The principle of ensuring that AI systems produce equitable outcomes across different user groups, mitigating systemic bias in data, design, or deployment.
* **Hallucinations**: Incorrect or fabricated outputs generated by AI models, often due to poor training data or model
  limitations.
* **Large Language Models (LLMs)**: Advanced AI models trained on vast text datasets to generate human-like language,
  requiring specific governance for risks like prompt injection.
* **Model Drift**: The degradation of an AI modelâ€™s performance due to changes in data context, usage patterns, or external environments after deployment.
* **Model Poisoning**: A specific type of attack where malicious data or modifications are introduced during model
  training to alter its behavior.
* **Non-deterministic Behavior**: AI model outputs that vary with changes in data or context, making predictability and
  assurance challenging.
* **Opaque Decision Logic**: The lack of interpretability in AI models, where the reasoning behind outputs is difficult
  to understand or explain.
* **Prompt Injection**: A type of adversarial attack targeting LLMs by crafting malicious inputs to manipulate or bypass
  model behavior.
* **Responsible AI (RAI)**: A strategic approach to designing, developing, and deploying AI systems in alignment with ethical values, fairness, accountability, and legal compliance.
* **Transparency**: The practice of making AI system processes, data sources, decision logic, and risks openly available and understandable to stakeholders, supporting oversight and accountability.

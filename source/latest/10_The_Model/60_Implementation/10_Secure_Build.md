### Secure Build

Secure Build practices form the foundation for trustworthy AI by ensuring that risks are addressed early—during model selection, development, and integration. Unlike traditional software builds, AI systems depend on data quality, third-party model provenance, and probabilistic behaviors that must be explicitly controlled. A secure build process incorporates defensible supply chain decisions, ethical considerations, and reproducible configurations. It mandates that all models—whether pre-trained or custom—are assessed not only for technical performance but also for licensing, robustness, and alignment with intended use. Effective implementation includes integrating automated security scans, adversarial robustness checks, and validation mechanisms into development pipelines. These controls help prevent the downstream amplification of vulnerabilities and reduce bias propagation. They also ensure the system remains observable, verifiable, and secure before deployment.

#### Objectives

- **Promote Secure Foundations**: Ensure responsible sourcing, secure coding, and defensible supply chain decisions are embedded in build practices.
- **Establish Model Accountability**: Verify licensing, purpose alignment, and robustness for all models before integration.
- **Automate Trust Checks**: Incorporate reproducibility, adversarial robustness, and validation into automated pipelines.

#### Streams

| Maturity Level                                                                                         | Stream A                                                                                                                                                                                                | Stream B                                                                                                                                            |
|--------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------|
| **1 – Establish awareness** with Governance and controls for foundation framework implementation.      | - **Ad hoc Model Selection**: Model sources selected without standard criteria. <br> - **Lack of Inventory**: Inventory is informal or outdated. <br> - **Missing Provenance**: Purpose and provenance of models are rarely documented.                                            | - **Unchecked Licensing**: License terms and dependencies rarely verified. <br> - **Vulnerability Gaps**: Known vulnerabilities not consistently scanned. <br> - **No Tooling**: No formal toolchain for validation. |
| **2 – Defined Practices** with security and governance practices are being documented and implemented. | - **Secure Guidelines**: Secure development guidelines include AI-specific considerations. <br> - **Basic Model Review**: Model reviews include basic ethical and compliance checks. <br> - **Inventory Control**: Inventory management is standardized but not automated.    | - **I/O Controls**: Input/output sanitization in place. <br> - **Versioning**: Models and datasets version-controlled. <br> - **Initial Validation**: Basic output validation initiated.                      |
| **3 – Continuously Manage Risk** with proactive governance and supply chain-level awareness.           | - **Formal Risk Reviews**: Formal risk assessments conducted for third-party and internal models. <br> - **Custody Controls**: Custody of AI assets is tracked and managed. <br> - **Supplier Assurance**: Attestations and compliance documents are requested from providers. | - **Adversarial Testing**: Adversarial testing is routinely performed. <br> - **CI/CD Integration**: AI checks are integrated into CI/CD pipelines. <br> - **Edge Case Validation**: Behavior under edge cases is validated.  |

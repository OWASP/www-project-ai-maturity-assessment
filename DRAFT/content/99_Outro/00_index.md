# Appendix

## Glossary

* **Adversarial Attacks**: Malicious attempts to manipulate AI model inputs to produce incorrect or harmful outputs,
  exploiting vulnerabilities in data or model behavior.
* **Agentic AI**: Advanced AI systems capable of autonomous decision-making and continuous evolution through feedback
  loops, requiring robust governance.
* **Bias**: Unintended or unfair preferences in AI outputs, often arising from skewed training data, algorithms, or
  human oversight, potentially perpetuating discrimination.
* **Data Drift**: Changes in the statistical properties of input data over time, which can degrade AI model performance
  or reliability.
* **Data Poisoning**: Deliberate manipulation or corruption of training data to compromise an AI model's integrity or
  outputs.
* **Explainability**: The ability to provide clear, understandable reasons for AI decisions, enabling stakeholders to
  comprehend and trust outcomes.
* **Fairness**: Ensuring AI systems provide equitable outcomes across diverse groups, mitigating biases in data or
  algorithms.
* **Hallucinations**: Incorrect or fabricated outputs generated by AI models, often due to poor training data or model
  limitations.
* **Large Language Models (LLMs)**: Advanced AI models trained on vast text datasets to generate human-like language,
  requiring specific governance for risks like prompt injection.
* **Model Drift**: Gradual degradation in an AI model's performance due to changes in data, context, or environment.
* **Model Poisoning**: A specific type of attack where malicious data or modifications are introduced during model
  training to alter its behavior.
* **Non-deterministic Behavior**: AI model outputs that vary with changes in data or context, making predictability and
  assurance challenging.
* **Opaque Decision Logic**: The lack of interpretability in AI models, where the reasoning behind outputs is difficult
  to understand or explain.
* **Prompt Injection**: A type of adversarial attack targeting LLMs by crafting malicious inputs to manipulate or bypass
  model behavior.
* **Responsible AI (RAI)**: The practice of designing, developing, and deploying AI systems that prioritize fairness,
  transparency, accountability, and ethical alignment.
* **Transparency**: Openly sharing information about AI system operations, including data sources, design, and
  decision-making processes, to ensure accountability.

## Governance Assessment Worksheet for AIMA

Below is a sample **Governance domain assessment worksheet** for AIMA, modeled after the OWASP SAMM Governance worksheet. It is organized by practice (Strategy & Metrics, Policy & Compliance, Education & Awareness) and grouped by maturity level. For each question, an assessor would mark **Yes or No** to indicate whether the organization currently fulfills that criterion. Achieving all “Yes” answers in Level 1 for a given practice indicates maturity Level 1 is attained; all Level 1 and Level 2 “Yes” indicates Level 2, and so on. (Partial “Yes” in the next level would be noted as a “+” as discussed.)

**Strategy & Metrics** – Aligning AI initiatives with business strategy and measuring AI program effectiveness.

| Maturity Level | Assessment Questions (Strategy & Metrics)                                                                                                           | Yes  | No   |
| -------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- | ---- | ---- |
| **Level 1**    | Does the organization have a basic AI strategy or governance program in place?                                                                      | \[ ] | \[ ] |
|                | Do business stakeholders understand the organization’s AI risk profile (the key risks of AI systems)?                                               | \[ ] | \[ ] |
|                | Are technical teams aware of the organization’s plans and roadmap for AI initiatives and governance?                                                | \[ ] | \[ ] |
|                | Has the organization identified or categorized its AI applications and data assets by risk or criticality?                                          | \[ ] | \[ ] |
| **Level 2**    | Are risk assessment ratings used to tailor AI governance activities (e.g. more oversight on higher-risk AI systems)?                                | \[ ] | \[ ] |
|                | Are AI project teams informed of and following requirements based on their project’s risk classification?                                           | \[ ] | \[ ] |
|                | Does the organization collect per-project data (e.g. resource usage, incidents, or costs) related to AI governance efforts?                         | \[ ] | \[ ] |
| **Level 3**    | Does the organization benchmark or regularly compare its AI program (investment, performance, or risk posture) against industry standards or peers? | \[ ] | \[ ] |

**Policy & Compliance** – Establishing AI policies and meeting legal/ethical requirements.

| Maturity Level | Assessment Questions (Policy & Compliance)                                                                                                                                              | Yes  | No   |
| -------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---- | ---- |
| **Level 1**    | Do project stakeholders know the compliance requirements applicable to their AI projects (e.g. privacy laws, ethical guidelines)?                                                       | \[ ] | \[ ] |
|                | Are AI-related compliance requirements (legal regulations, industry standards, internal policies) explicitly considered during AI project planning and development?                     | \[ ] | \[ ] |
| **Level 2**    | Has the organization defined and implemented a set of AI policies and standards to guide AI development and deployment?                                                                 | \[ ] | \[ ] |
|                | Can AI project teams request or undergo audits/reviews to confirm compliance with AI policies and standards?                                                                            | \[ ] | \[ ] |
|                | Are AI projects periodically audited or assessed to ensure a baseline compliance with the established AI policies and external regulations?                                             | \[ ] | \[ ] |
| **Level 3**    | Does the organization systematically collect and manage evidence of AI compliance (e.g. audit results, documentation) to demonstrate accountability (for internal needs or regulators)? | \[ ] | \[ ] |

**Education & Awareness** – Training and guiding personnel on secure and ethical AI.

| Maturity Level | Assessment Questions (Education & Awareness)                                                                                                                                                                             | Yes  | No   |
| -------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---- | ---- |
| **Level 1**    | Have most relevant staff (developers, data scientists, etc.) received basic awareness training on AI security, privacy, and ethics?                                                                                      | \[ ] | \[ ] |
|                | Does each AI project team have access to documented best practices or guidelines for secure and responsible AI development?                                                                                              | \[ ] | \[ ] |
| **Level 2**    | Do individuals in key roles (developers, testers, project managers, data scientists) receive role-specific training or guidance on AI security and ethical responsibilities?                                             | \[ ] | \[ ] |
|                | Are expert resources (e.g. AI security or ethics champions/coaches) available to consult with project teams when needed?                                                                                                 | \[ ] | \[ ] |
| **Level 3**    | Does the organization maintain a robust knowledge-sharing program or repository (e.g. an internal AI governance knowledge base, forums, centers of excellence) to continuously update guidance and support for AI teams? | \[ ] | \[ ] |

Each section above corresponds to one of the Governance practices in AIMA. An assessor would review each question with stakeholders, mark Yes/No, and then determine the maturity level achieved. For instance, if **Strategy & Metrics** has all Level 1 and Level 2 questions answered “Yes,” but not all of Level 3, the score would be **Level 2+** for that practice. This worksheet format ensures a **structured yet flexible** assessment: it captures granular practices through yes/no checklists while mirroring the SAMM style that stakeholders may already be familiar with, now applied to the domain of AI.


# Preface

In recent years, innovation has accelerated at an unprecedented pace. However, our collective ability to ensure that AI systems are secure, trustworthy and aligned with human values has struggled to keep up.

The need for structured guidance across the software industry is nothing new. In 2008, for example, OWASP SAMM introduced a pragmatic maturity model that helped thousands of organisations integrate security into their software development lifecycle. Today, we are at a similar inflection point with artificial intelligence. The OWASP AI Maturity Assessment (AIMA) is our response.

As AI technologies become integral to products, services and critical infrastructure, the stakes are higher than ever. The industry is witnessing a surge in AI adoption, accompanied by heightened public scrutiny and evolving regulatory requirements. Organisations can no longer afford to be reactive when it comes to managing AI risks. Instead, there is a growing demand for actionable frameworks that empower teams to build AI systems responsibly, balancing innovation with oversight, agility with accountability, and technical excellence with ethical considerations.

AIMA adapts the foundational concepts of OWASP SAMM to the unique realities of AI lifecycle engineering. It extends traditional application security controls to encompass safeguards for data provenance, model robustness, privacy, fairness and transparency.

This document is intended for CISOs, AI/ML engineers, product leads, auditors and policymakers, helping them to translate high-level principles into day-to-day engineering decisions. Each maturity level is linked to tangible activities, artefacts, and metrics, enabling incremental improvement rather than disruptive transformation.

Version 1.0 includes eight assessment domains, detailed maturity criteria and a worksheet to support internal evaluations and third-party assessments. This helps you to identify and mitigate risks across your AI supply chain.

The strength of a maturity model depends on the community that shapes it. We encourage open collaboration through GitHub issues, pull requests, pilot assessments and conference discussions. Your feedback will help us to refine the scoring criteria, expand the domain-specific guidance and promote technical rigour across the various use cases.

We would like to express our deepest gratitude to the OWASP Foundation, the SAMM core team, the early reviewers from academia and industry, and the volunteers who contributed test cases, glossary entries and real-world anecdotes.

We view this release as a living document. It will evolve in line with new research, regulatory changes and field experience, and we look forward to receiving your valuable input as we continue to develop it.

Onward,  
Matteo Meucci & Philippe Schrettenbrunner   
_Project Co-Leads, OWASP AI Maturity Assessment_

## Authors

#### Project Leads
* Matteo Meucci
* Philippe Schrettenbrunner

#### Contributors
* Arvinda Gangadhararao
* Sana Zia Hassan
* Abhinavdutt Singh
* Marco Denti
* Andrea Luigi Vitali
* Hubert Jackowski
* Keren Katz
* Montadhar Rekaya

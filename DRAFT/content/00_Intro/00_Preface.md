# Preface

In recent years, innovation has moved faster than ever—but our ability to ensure that AI systems are secure, reliable, and aligned with human values hasn’t kept pace.

Structured guidance isn’t new to the software industry. Back in 2008, OWASP SAMM offered a practical maturity model that helped countless organisations embed security into their development processes. Today, with AI becoming a core part of products, infrastructure and everyday decisions, we’re at a similar crossroads. The OWASP AI Maturity Assessment (AIMA) is our response.

As AI technologies become integral to products, services and critical infrastructure, the stakes are higher than ever. The industry is witnessing a surge in AI adoption, accompanied by heightened public scrutiny and evolving regulatory requirements. Organisations can no longer afford to be reactive when it comes to managing AI risks. Instead, there is a growing demand for actionable frameworks that empower teams to build AI systems responsibly, balancing innovation with oversight, agility with accountability, and technical excellence with ethical considerations.

AIMA adapts the foundational concepts of OWASP SAMM to the unique realities of AI lifecycle engineering. It extends traditional application security controls to encompass safeguards for data provenance, model robustness, privacy, fairness and transparency.

This document is intended for CISOs, AI/ML engineers, product leads, auditors and policymakers, helping them to translate high-level principles into day-to-day engineering decisions. Each maturity level is linked to tangible activities, artefacts, and metrics, enabling incremental improvement rather than disruptive transformation.

Version 1.0 introduces eight assessment areas, with detailed criteria and a worksheet for internal use or third-party evaluations. It’s designed to help you spot gaps and manage risk across the entire AI lifecycle.

Of course, a model is only as strong as the community behind it. That’s why we welcome your input—whether through GitHub Issues, pilot testing, or live discussions. Your feedback will shape future versions and help refine the scoring, guidance and coverage.

We would like to express our deepest gratitude to the OWASP Foundation, the SAMM core team, the early reviewers from academia and industry, and the volunteers who contributed test cases, glossary entries and real-world anecdotes.

We view this release as a living document. It will evolve in line with new research, regulatory changes and field experience, and we look forward to receiving your valuable input as we continue to develop it.

Onward,  
Matteo Meucci & Philippe Schrettenbrunner   
_Project Co-Leads, OWASP AI Maturity Assessment_

## Authors

* Matteo Meucci
* Philippe Schrettenbrunner
* Arvinda Gangadhararao
* Sana Zia Hassan
* Abhinavdutt Singh
* Marco Denti
* Andrea Luigi Vitali
* Hubert Jackowski
* Keren Katz
* Montadhar Rekaya

We also want to thank everyone in the wider OWASP AIMA community — especially those in the Slack channel — who shared feedback, ideas, or encouragement along the way. Your input helped shape this project.
